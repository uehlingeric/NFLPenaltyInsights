{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalty Prediction Models\n",
    "\n",
    "## Introduction\n",
    "This notebook aims to build a series of Negative Binomial Regression models to predict the count of each penalty type for a specific NFL game scenario. Each model will correspond to a different type of penalty.\n",
    "\n",
    "## Data Preparation\n",
    "We will start by loading and preparing the dataset, which includes encoding categorical variables and aggregating penalty counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "from statsmodels.genmod.families import NegativeBinomial\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "First, we load the necessary data and preprocess it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>team_id</th>\n",
       "      <th>opp_id</th>\n",
       "      <th>penalty</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>ref_crew</th>\n",
       "      <th>home</th>\n",
       "      <th>postseason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009_1_TEN_PIT</td>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>Def_Unnecessary_Roughness</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Bill Leavy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009_1_TEN_PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>PIT</td>\n",
       "      <td>Off_Illegal_Formation</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Bill Leavy</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009_1_TEN_PIT</td>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>Off_Holding</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Bill Leavy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009_1_TEN_PIT</td>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>Off_Holding</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Bill Leavy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009_1_TEN_PIT</td>\n",
       "      <td>PIT</td>\n",
       "      <td>TEN</td>\n",
       "      <td>Def_Pass_Interference</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>Bill Leavy</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          game_id team_id opp_id                    penalty  year  week  \\\n",
       "0  2009_1_TEN_PIT     PIT    TEN  Def_Unnecessary_Roughness  2009     1   \n",
       "1  2009_1_TEN_PIT     TEN    PIT      Off_Illegal_Formation  2009     1   \n",
       "2  2009_1_TEN_PIT     PIT    TEN                Off_Holding  2009     1   \n",
       "3  2009_1_TEN_PIT     PIT    TEN                Off_Holding  2009     1   \n",
       "4  2009_1_TEN_PIT     PIT    TEN      Def_Pass_Interference  2009     1   \n",
       "\n",
       "     ref_crew home postseason  \n",
       "0  Bill Leavy  Yes         No  \n",
       "1  Bill Leavy   No         No  \n",
       "2  Bill Leavy  Yes         No  \n",
       "3  Bill Leavy  Yes         No  \n",
       "4  Bill Leavy  Yes         No  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/processed/penalties.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Count the frequency of each penalty type\n",
    "penalties_count = df['penalty'].value_counts()\n",
    "\n",
    "# Filter for penalties that occur at least 50 times\n",
    "frequent_penalties = penalties_count[penalties_count >= 50].index.tolist()\n",
    "\n",
    "# Exclude special teams penalties and filter by frequent penalties\n",
    "penalties_data = df[(df['phase'] != 'ST') & (df['penalty'].isin(frequent_penalties))]\n",
    "\n",
    "df_filtered = penalties_data.loc[:, ['game_id', 'team_id', 'opp_id', 'penalty', 'year', 'week', 'ref_crew', 'home', 'postseason']]\n",
    "\n",
    "# Aggregate data to get the count of each penalty type per game and team\n",
    "df_grouped = df_filtered.groupby(['game_id', 'team_id', 'opp_id', 'year', 'week', 'ref_crew', 'home', 'postseason', 'penalty']).size().reset_index(name='count')\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "for column in ['team_id', 'opp_id', 'ref_crew', 'home', 'postseason', 'penalty']:\n",
    "    le = LabelEncoder()\n",
    "    df_grouped[column] = le.fit_transform(df_grouped[column])\n",
    "    label_encoders[column] = le\n",
    "\n",
    "# Display basic information and the first few rows of the dataset\n",
    "df_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "For each unique penalty type, we will construct a Negative Binomial Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty: Off_Holding\n",
      "Weights: Intercept    -56.036432\n",
      "team_id        0.000627\n",
      "opp_id         0.000716\n",
      "year           0.028097\n",
      "week          -0.008158\n",
      "ref_crew       0.000468\n",
      "home           0.028761\n",
      "postseason    -0.167842\n",
      "dtype: float64\n",
      "MSE: 1.136740533579205\n",
      "R^2: 0.05256882622285752\n",
      "\n",
      "---\n",
      "\n",
      "Penalty: Off_False_Start\n",
      "Weights: Intercept    -29.218550\n",
      "team_id       -0.000827\n",
      "opp_id        -0.001180\n",
      "year           0.014800\n",
      "week          -0.002910\n",
      "ref_crew       0.000070\n",
      "home          -0.002231\n",
      "postseason    -0.113933\n",
      "dtype: float64\n",
      "MSE: 1.0853138637897506\n",
      "R^2: 0.017467152606337133\n",
      "\n",
      "---\n",
      "\n",
      "Penalty: Def_Pass_Interference\n",
      "Weights: Intercept    -51.618504\n",
      "team_id       -0.000964\n",
      "opp_id        -0.001356\n",
      "year           0.025811\n",
      "week          -0.003856\n",
      "ref_crew       0.000266\n",
      "home          -0.038040\n",
      "postseason    -0.053744\n",
      "dtype: float64\n",
      "MSE: 0.4962166675359705\n",
      "R^2: 0.057064251375285036\n",
      "\n",
      "---\n",
      "\n",
      "Penalty: Def_Holding\n",
      "Weights: Intercept    -56.940973\n",
      "team_id        0.001148\n",
      "opp_id         0.000794\n",
      "year           0.028430\n",
      "week          -0.003919\n",
      "ref_crew      -0.000628\n",
      "home          -0.035687\n",
      "postseason    -0.078879\n",
      "dtype: float64\n",
      "MSE: 0.5264149893965498\n",
      "R^2: 0.05878453308107001\n",
      "\n",
      "---\n",
      "\n",
      "Penalty: Def_Offside\n",
      "Weights: Intercept    -21.591907\n",
      "team_id        0.000572\n",
      "opp_id         0.001733\n",
      "year           0.010891\n",
      "week          -0.002201\n",
      "ref_crew      -0.000523\n",
      "home          -0.014720\n",
      "postseason    -0.162443\n",
      "dtype: float64\n",
      "MSE: 0.6003471414315623\n",
      "R^2: 0.015496369263718557\n",
      "\n",
      "---\n",
      "\n",
      "Overall Ensemble MSE: 0.7690066391466076\n",
      "Overall Ensemble R^2: 0.04027622650985365\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store models\n",
    "models = {}\n",
    "\n",
    "# Define predictor variables\n",
    "predictors = ['team_id', 'opp_id', 'year', 'week', 'ref_crew', 'home', 'postseason']\n",
    "\n",
    "# Identify the top 5 most common penalty types\n",
    "top_penalty_codes = df_grouped['penalty'].value_counts().nlargest(5).index.tolist()\n",
    "\n",
    "# Store MSE and R-squared values for overall evaluation\n",
    "overall_mse = []\n",
    "overall_r2 = []\n",
    "\n",
    "# Train and evaluate a model for each of the top 5 penalty types\n",
    "for penalty_code in top_penalty_codes:\n",
    "    # Filter data for the current penalty type\n",
    "    df_penalty = df_grouped[df_grouped['penalty'] == penalty_code]\n",
    "    \n",
    "    # Model formula\n",
    "    formula = 'count ~ ' + ' + '.join(predictors)\n",
    "    \n",
    "    # Fit the model with explicit alpha to avoid warnings\n",
    "    model = glm(formula, data=df_penalty, family=NegativeBinomial(alpha=1.0)).fit()\n",
    "    models[penalty_code] = model\n",
    "    \n",
    "    # Predict on the training data\n",
    "    y_pred = model.predict(df_penalty[predictors])\n",
    "    y_true = df_penalty['count']\n",
    "    \n",
    "    # Calculate MSE and R-squared\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    # Append to overall lists\n",
    "    overall_mse.append(mse)\n",
    "    overall_r2.append(r2)\n",
    "    \n",
    "    # Print the model's evaluation\n",
    "    print(f\"Penalty: {label_encoders['penalty'].inverse_transform([penalty_code])[0]}\")\n",
    "    print(f\"Weights: {model.params}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"R^2: {r2}\")\n",
    "    print(\"\\n---\\n\")\n",
    "\n",
    "# Calculate and print overall ensemble model's MSE and R^2\n",
    "ensemble_mse = np.mean(overall_mse)\n",
    "ensemble_r2 = np.mean(overall_r2)\n",
    "print(f\"Overall Ensemble MSE: {ensemble_mse}\")\n",
    "print(f\"Overall Ensemble R^2: {ensemble_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function\n",
    "This function takes game details as input and predicts the penalty counts for each type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Off_Holding</th>\n",
       "      <th>Off_False_Start</th>\n",
       "      <th>Def_Pass_Interference</th>\n",
       "      <th>Def_Holding</th>\n",
       "      <th>Def_Offside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted Count</th>\n",
       "      <td>2.174033</td>\n",
       "      <td>1.920161</td>\n",
       "      <td>1.610521</td>\n",
       "      <td>1.691706</td>\n",
       "      <td>1.573771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Off_Holding  Off_False_Start  Def_Pass_Interference  \\\n",
       "Predicted Count     2.174033         1.920161               1.610521   \n",
       "\n",
       "                 Def_Holding  Def_Offside  \n",
       "Predicted Count     1.691706     1.573771  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_penalties(team_id, opp_id, year, week, ref_crew, home, postseason):\n",
    "    # Encode input data\n",
    "    input_data = {\n",
    "        'team_id': label_encoders['team_id'].transform([team_id])[0],\n",
    "        'opp_id': label_encoders['opp_id'].transform([opp_id])[0],\n",
    "        'year': year,\n",
    "        'week': week,\n",
    "        'ref_crew': label_encoders['ref_crew'].transform([ref_crew])[0],\n",
    "        'home': label_encoders['home'].transform([home])[0],\n",
    "        'postseason': label_encoders['postseason'].transform([postseason])[0]\n",
    "    }\n",
    "    \n",
    "    predictions = {}\n",
    "    for penalty_code, model in models.items():\n",
    "        features_df = pd.DataFrame([input_data])\n",
    "        predicted_count = model.predict(features_df)[0]\n",
    "        penalty_type = label_encoders['penalty'].inverse_transform([penalty_code])[0]\n",
    "        predictions[penalty_type] = max(0, predicted_count)  # Ensure non-negative predictions\n",
    "    \n",
    "    return pd.DataFrame([predictions], index=['Predicted Count'])\n",
    "\n",
    "# Example prediction\n",
    "predict_penalties('DAL', 'SEA', 2023, 10, 'Bill Leavy', 'Yes', 'No')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
