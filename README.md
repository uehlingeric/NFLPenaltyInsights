# NFL Penalty Data Analysis Project

## Project Overview

This project focuses on the machine learning analysis of NFL penalties to predict their occurrence and evaluate their effectiveness in terms of points, wins and final standing. Through comprehensive data collection, cleaning, and analysis, we aim to provide insights into how penalties influence the game's outcome and offer predictive models that could be useful for teams, analysts, and fans alike.

## Data Collection

The data collection process involved writing custom scripts to scrape NFL game and penalty data from various sources. This process was divided into several steps:

- **Identifying Missing Data (`missing.py`):** This script checks for any missing game data by comparing our existing dataset with the list of all NFL games within our study's timeframe. It generates a list of URLs (games) that need to be scraped.
- **Scraping Game Data (`scrape_games.py`):** Utilizing the list generated by `missing.py`, this script scrapes detailed game data from specified URLs. It collects information critical for our analysis, including game outcomes, teams, dates, and more.
- **Scraping Penalty Data (`scrape_penalties.py`):** This script is dedicated to extracting detailed information on penalties from each game. It collects data such as penalty type, penalized team, game impact, and more.

## Data Cleaning and Schema Finalization

After collecting the data, the next crucial step was cleaning and structuring it according to our finalized schema. This phase was collaborative, with contributions from team members to ensure data quality and consistency. The process involved:

- **Data Cleaning:** Addressing missing values, removing outliers, and standardizing formats across the dataset.
- **Schema Design:** Finalizing a database schema that supports efficient analysis and machine learning model development. This included defining the structure for storing games, penalties, teams, and their relationships.

## Team Contributions

- **Eric:** Focused on the data collection phase, Eric wrote the `missing.py`, `scrape_games.py`, and `scrape_penalties.py` scripts. 
- **Rohan and Leo:** Worked collaboratively on cleaning the data and finalizing the schema. 

## How to Use This Project

### Scraping
To collect the data needed for analysis, follow these steps:
1. **Run `missing.py`:** Identifies the games that need data collection.
2. **Execute `scrape_games.py`:** Collects game data based on the output from `missing.py`.
3. **Run `scrape_penalties.py`:** Collects penalty data and is not related to `missing.py`.

## Dependencies

This project requires the following libraries:
- BeautifulSoup
- Selenium
- pandas
- requests

You can install these dependencies using pip:

```bash
pip install beautifulsoup4 selenium pandas requests
```

Additionally, you will need the appropriate ChromeDriver for Selenium.

## Future Work

We have completed the scraping process and are nearing the end of the cleaning process. The next steps involve developing our models for future analysis, which will allow us to predict penalties and evaluate their impact more effectively.

## Credits

- **Eric:** Data collection and scripting.
- **Rohan:** Data cleaning and schema finalization.
- **Leo:** Data cleaning and schema finalization.
